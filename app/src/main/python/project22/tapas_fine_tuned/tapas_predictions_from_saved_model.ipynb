{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evgenynazarenko/opt/anaconda3/envs/coremltools-env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import TapasTokenizer\n",
    "\n",
    "\n",
    "# load model\n",
    "model = torch.load('schedule-tapas-small-finetuned-sqa.pth')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# initialize the tokenizer\n",
    "tokenizer = TapasTokenizer.from_pretrained(\"google/tapas-small-finetuned-sqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Time       Monday      Tuesday    Wednesday     Thursday       Friday\n",
      "0    9          TCS        Logic          TCS     Calculus           MM\n",
      "1   11          SSA  Project 2-2  Project 2-2  Project 2-2          TCS\n",
      "2   13           MM          SSA          TCS          SSA          TCS\n",
      "3   15  Project 2-2     Calculus           MM        Logic     Calculus\n",
      "4   17           MM          TCS     Calculus          SSA  Project 2-2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# load the weekly schedule table from csv\n",
    "table_schedule = pd.read_csv(\"student_schedule_week.csv\").astype(str)\n",
    "\n",
    "print(table_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "def compute_prediction_sequence(model, data, device):\n",
    "  \"\"\"Computes predictions using model's answers to the previous questions.\"\"\"\n",
    "  \n",
    "  # prepare data\n",
    "  input_ids = data[\"input_ids\"].to(device)\n",
    "  attention_mask = data[\"attention_mask\"].to(device)\n",
    "  token_type_ids = data[\"token_type_ids\"].to(device)\n",
    "\n",
    "  all_logits = []\n",
    "  prev_answers = None\n",
    "\n",
    "  num_batch = data[\"input_ids\"].shape[0]\n",
    "  \n",
    "  for idx in range(num_batch):\n",
    "    \n",
    "    if prev_answers is not None:\n",
    "        coords_to_answer = prev_answers[idx]\n",
    "        # Next, set the label ids predicted by the model\n",
    "        prev_label_ids_example = token_type_ids_example[:,3] # shape (seq_len,)\n",
    "        model_label_ids = np.zeros_like(prev_label_ids_example.cpu().numpy()) # shape (seq_len,)\n",
    "\n",
    "        # for each token in the sequence:\n",
    "        token_type_ids_example = token_type_ids[idx] # shape (seq_len, 7)\n",
    "        for i in range(model_label_ids.shape[0]):\n",
    "          segment_id = token_type_ids_example[:,0].tolist()[i]\n",
    "          col_id = token_type_ids_example[:,1].tolist()[i] - 1\n",
    "          row_id = token_type_ids_example[:,2].tolist()[i] - 1\n",
    "          if row_id >= 0 and col_id >= 0 and segment_id == 1:\n",
    "            model_label_ids[i] = int(coords_to_answer[(col_id, row_id)])\n",
    "\n",
    "        # set the prev label ids of the example (shape (1, seq_len) )\n",
    "        token_type_ids_example[:,3] = torch.from_numpy(model_label_ids).type(torch.long).to(device)   \n",
    "\n",
    "    prev_answers = {}\n",
    "    # get the example\n",
    "    input_ids_example = input_ids[idx] # shape (seq_len,)\n",
    "    attention_mask_example = attention_mask[idx] # shape (seq_len,)\n",
    "    token_type_ids_example = token_type_ids[idx] # shape (seq_len, 7)\n",
    "    # forward pass to obtain the logits\n",
    "    outputs = model(input_ids=input_ids_example.unsqueeze(0), \n",
    "                    attention_mask=attention_mask_example.unsqueeze(0), \n",
    "                    token_type_ids=token_type_ids_example.unsqueeze(0))\n",
    "    logits = outputs.logits\n",
    "    all_logits.append(logits)\n",
    "\n",
    "    # convert logits to probabilities (which are of shape (1, seq_len))\n",
    "    dist_per_token = torch.distributions.Bernoulli(logits=logits)\n",
    "    probabilities = dist_per_token.probs * attention_mask_example.type(torch.float32).to(dist_per_token.probs.device) \n",
    "\n",
    "    # Compute average probability per cell, aggregating over tokens.\n",
    "    # Dictionary maps coordinates to a list of one or more probabilities\n",
    "    coords_to_probs = collections.defaultdict(list)\n",
    "    prev_answers = {}\n",
    "    for i, p in enumerate(probabilities.squeeze().tolist()):\n",
    "      segment_id = token_type_ids_example[:,0].tolist()[i]\n",
    "      col = token_type_ids_example[:,1].tolist()[i] - 1\n",
    "      row = token_type_ids_example[:,2].tolist()[i] - 1\n",
    "      if col >= 0 and row >= 0 and segment_id == 1:\n",
    "        coords_to_probs[(col, row)].append(p)\n",
    "\n",
    "    # Next, map cell coordinates to 1 or 0 (depending on whether the mean prob of all cell tokens is > 0.5)\n",
    "    coords_to_answer = {}\n",
    "    for key in coords_to_probs:\n",
    "      coords_to_answer[key] = np.array(coords_to_probs[key]).mean() > 0.5\n",
    "    prev_answers[idx+1] = coords_to_answer\n",
    "    \n",
    "  logits_batch = torch.cat(tuple(all_logits), 0)\n",
    "  \n",
    "  return logits_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "our_queries=[\"What subject is at 11 on Tuesday?\",\"What is the next lecture?\"]\n",
    "inputs = tokenizer(table=table_schedule, queries=our_queries, padding='max_length', return_tensors=\"pt\")\n",
    "logits = compute_prediction_sequence(model, inputs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predicted_answer_coordinates, = tokenizer.convert_logits_to_predictions(inputs, logits.cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Friday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>TCS</td>\n",
       "      <td>Logic</td>\n",
       "      <td>TCS</td>\n",
       "      <td>Calculus</td>\n",
       "      <td>MM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>SSA</td>\n",
       "      <td>Project 2-2</td>\n",
       "      <td>Project 2-2</td>\n",
       "      <td>Project 2-2</td>\n",
       "      <td>TCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>MM</td>\n",
       "      <td>SSA</td>\n",
       "      <td>TCS</td>\n",
       "      <td>SSA</td>\n",
       "      <td>TCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>Project 2-2</td>\n",
       "      <td>Calculus</td>\n",
       "      <td>MM</td>\n",
       "      <td>Logic</td>\n",
       "      <td>Calculus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>MM</td>\n",
       "      <td>TCS</td>\n",
       "      <td>Calculus</td>\n",
       "      <td>SSA</td>\n",
       "      <td>Project 2-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Time       Monday      Tuesday    Wednesday     Thursday       Friday\n",
       "0    9          TCS        Logic          TCS     Calculus           MM\n",
       "1   11          SSA  Project 2-2  Project 2-2  Project 2-2          TCS\n",
       "2   13           MM          SSA          TCS          SSA          TCS\n",
       "3   15  Project 2-2     Calculus           MM        Logic     Calculus\n",
       "4   17           MM          TCS     Calculus          SSA  Project 2-2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "What subject is at 11 on Tuesday?\n",
      "Predicted answer: Project 2-2\n",
      "What is the next lecture?\n",
      "Predicted answer: SSA\n"
     ]
    }
   ],
   "source": [
    "# handy helper function in case inference on Pandas dataframe\n",
    "answers = []\n",
    "for coordinates in predicted_answer_coordinates:\n",
    "  if len(coordinates) == 1:\n",
    "    # only a single cell:\n",
    "    answers.append(table_schedule.iat[coordinates[0]])\n",
    "  else:\n",
    "    # multiple cells\n",
    "    cell_values = []\n",
    "    for coordinate in coordinates:\n",
    "      cell_values.append(table_schedule.iat[coordinate])\n",
    "    answers.append(\", \".join(cell_values))\n",
    "\n",
    "display(table_schedule)\n",
    "print(\"\")\n",
    "for query, answer in zip(our_queries, answers):\n",
    "  print(query)\n",
    "  print(\"Predicted answer: \" + answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coremltools-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}